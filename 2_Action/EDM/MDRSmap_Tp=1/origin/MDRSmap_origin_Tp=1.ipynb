{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/yitsung/Desktop/MasterThesis/EDM_Function/BinaryClassfication/')\n",
    "# sys.path.append('/raid/ytchang/MasterThesis/EDM_Function/BinaryClassfication/')\n",
    "\n",
    "from EDMfunction_origin import *\n",
    "# from EDMfunction_OSPS import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "TICKER = 2330\n",
    "TP = 1\n",
    "TARGET = f'y_{TP}'\n",
    "\n",
    "data = pd.read_csv('/Users/yitsung/Desktop/MasterThesis/data/TaiwanStockData_Top100_EMA')\n",
    "# data = pd.read_csv('/raid/ytchang/MasterThesis/data/TaiwanStockData_Top100_EMA')\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data #\n",
    "ticker_data = data[data['ticker']==TICKER].reset_index(drop=True)\n",
    "ticker_data = ticker_data.drop(columns=['ticker'])\n",
    "\n",
    "# SMA-P/P, binary classification #\n",
    "ticker_data[f'y_{TP}'] = ticker_data['close'].rolling(window=TP).mean()\n",
    "ticker_data[f'y_{TP}'] = ticker_data[f'y_{TP}'].shift(-TP)\n",
    "ticker_data = ticker_data.dropna().reindex()\n",
    "ticker_data[f'y_{TP}'] = ((ticker_data[f'y_{TP}'] - ticker_data['close']) >= 0).astype(int)\n",
    "\n",
    "origi_data = ticker_data.copy() # Dataframe for validation\n",
    "\n",
    "# Restore to a dataframe without disclosing future information. #\n",
    "ticker_data[f'y_{TP}'] = ticker_data[f'y_{TP}'].shift(TP)\n",
    "ticker_data = ticker_data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splite Library and Prediction #\n",
    "Library = ticker_data[ticker_data['Date'] <= '2023-06-30'] # the last prediction from Library is 6/30\n",
    "Prediction = ticker_data[(ticker_data['Date'] >= '2023-07-01')&(ticker_data['Date'] <= '2023-10-31')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "KN = 5\n",
    "EMAX = 10\n",
    "MAXLAG = 10\n",
    "THETA_SEQ = [1,2,4,7,11,16,22]\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Theta     Score                                              Param\n",
      "0     1  0.525296  [{'C': 50, 'fit_intercept': True, 'intercept_s...\n",
      "1     2  0.528643  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.520239  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "3     7  0.521849  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "4    11  0.511822  [{'C': 0.1, 'fit_intercept': True, 'intercept_...\n",
      "5    16  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "6    22  0.511822  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "\n",
      " ACC: 0.4939759036144578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create a dataframe for prediction results. ###\n",
    "Date = origi_data['Date'][(origi_data['Date']>='2023-07-01')&(origi_data['Date']<='2023-10-31')].reset_index(drop=True)\n",
    "Observations = origi_data[TARGET][(origi_data['Date']>='2023-07-01')&(origi_data['Date']<='2023-10-31')].reset_index(drop=True)\n",
    "\n",
    "EDM_result = pd.DataFrame(Date)\n",
    "EDM_result['Observations'] = Observations\n",
    "EDM_result['Predictions'] = None\n",
    "\n",
    "### Starting from Pred[0] (include searching views for EDM) ###\n",
    "th=0\n",
    "Lib_Pred_df = ConcateLibPred(Library=Library, Prediction=Prediction, th=th)\n",
    "Lib_Pred_df = DataNormalize(Lib_Pred_df=Lib_Pred_df)\n",
    "\n",
    "formatted_columns, train_feature = EDM_FeatureProcessing(data=Lib_Pred_df, target=TARGET)\n",
    "TargetOED, TargetOED_rho = EDM_TargetOED(data=Lib_Pred_df, target=TARGET, valid_interval=60)\n",
    "f_selec = EDM_FeatureSelection(data=Lib_Pred_df, target=TARGET, \n",
    "                               train_feature=train_feature, TargetOED=TargetOED, \n",
    "                               E_max=EMAX)\n",
    "Embed_df, ML_df = EDM_CreateNewDF(data=Lib_Pred_df, target=TARGET, f_selec=f_selec, \n",
    "                                  max_lag=MAXLAG, th=th)\n",
    "rs_score = EDM_RandomSimplex(Embed_df=Embed_df, target=TARGET, targetOED=TargetOED, \n",
    "                             valid_interval=60, kmax=10000, kn=KN)\n",
    "dmatrix = EDM_WeightedDistanceMatrix(Embed_df=Embed_df, rs_score=rs_score)\n",
    "result_ls, theta, param = EDM_ModelSelection(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                                             theta_seq=THETA_SEQ, Tp=TP)\n",
    "model = EDM_TrainningModel(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                           theta=theta, param=param, Tp=TP)\n",
    "\n",
    "X_pred = np.array(ML_df.iloc[-1]).reshape(1, -1)\n",
    "y_pred = model.predict(X_pred)\n",
    "y_pred = y_pred[0]\n",
    "\n",
    "EDM_result.loc[th, 'Predictions'] = y_pred\n",
    "# print(f\"{EDM_result['Date'][th]}: finished\")\n",
    "\n",
    "### Predict the remaining ###\n",
    "for th in range(1, len(Prediction)):\n",
    "    Library = UnderSampling(Library=Library, target=TARGET) # only for EDMfunction_origin\n",
    "    Lib_Pred_df = ConcateLibPred(Library=Library, Prediction=Prediction, th=th)\n",
    "    Lib_Pred_df = DataNormalize(Lib_Pred_df=Lib_Pred_df)\n",
    "    Embed_df, ML_df = EDM_CreateNewDF(data=Lib_Pred_df, target=TARGET, f_selec=f_selec, \n",
    "                                      max_lag=MAXLAG, th=th)\n",
    "    dmatrix = EDM_WeightedDistanceMatrix(Embed_df=Embed_df, rs_score=rs_score)\n",
    "    model = EDM_TrainningModel(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                               theta=theta, param=param, Tp=TP)\n",
    "\n",
    "    X_pred = np.array(ML_df.iloc[-1]).reshape(1, -1)\n",
    "    y_pred = model.predict(X_pred)\n",
    "    y_pred = y_pred[0]\n",
    "\n",
    "    EDM_result.loc[th, 'Predictions'] = y_pred\n",
    "    # print(f\"{EDM_result['Date'][th]}: finished\")\n",
    "\n",
    "EDM_result.dropna(inplace=True)\n",
    "ACC = len(EDM_result[EDM_result['Predictions'] == EDM_result['Observations']]) / len(EDM_result['Observations'])\n",
    "print(f'\\n ACC: {ACC}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Observations Predictions\n",
       "0  2023-07-03             1         0.0\n",
       "1  2023-07-04             0         1.0\n",
       "2  2023-07-05             0         0.0\n",
       "3  2023-07-06             1         0.0\n",
       "4  2023-07-07             1         1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDM_result.to_csv(f'{TICKER}_MDRSmap_Tp={TP}_ResultOnce.csv', index=False)\n",
    "EDM_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 5 times on one stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################\n",
    "TICKER = 2330\n",
    "TP = 1\n",
    "TARGET = f'y_{TP}'\n",
    "\n",
    "data = pd.read_csv('/Users/yitsung/Desktop/MasterThesis/data/TaiwanStockData_Top100_EMA')\n",
    "# data = pd.read_csv('/raid/ytchang/MasterThesis/data/TaiwanStockData_Top100_EMA')\n",
    "###########################################################################################\n",
    "\n",
    "##############################\n",
    "KN = 5\n",
    "EMAX = 10\n",
    "MAXLAG = 10\n",
    "THETA_SEQ = [1,2,4,7,11,16,22]\n",
    "##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Theta     Score                                              Param\n",
      "0     1  0.530395  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "1     2  0.530395  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.523658  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "3     7  0.511822  [{'C': 0.1, 'fit_intercept': True, 'intercept_...\n",
      "4    11  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "5    16  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "6    22  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "\n",
      " 1 of 5 ACC: 0.4939759036144578\n",
      "\n",
      "  Theta     Score                                              Param\n",
      "0     1  0.528728  [{'C': 50, 'fit_intercept': True, 'intercept_s...\n",
      "1     2  0.528657  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.530338  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "3     7  0.516778  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "4    11  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "5    16  0.511822  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "6    22  0.511822  [{'C': 50, 'fit_intercept': True, 'intercept_s...\n",
      "\n",
      " 2 of 5 ACC: 0.40963855421686746\n",
      "\n",
      "  Theta     Score                                              Param\n",
      "0     1  0.527019  [{'C': 50, 'fit_intercept': True, 'intercept_s...\n",
      "1     2  0.530466  [{'C': 0.1, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.533799  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "3     7  0.511822  [{'C': 0.1, 'fit_intercept': True, 'intercept_...\n",
      "4    11  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "5    16  0.515183  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "6    22  0.511822  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "\n",
      " 3 of 5 ACC: 0.4939759036144578\n",
      "\n",
      "  Theta     Score                                              Param\n",
      "0     1   0.52531  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "1     2  0.537146  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.528671  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "3     7  0.513417  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "4    11  0.515155  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "5    16  0.511822  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "6    22  0.513488  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "\n",
      " 4 of 5 ACC: 0.4939759036144578\n",
      "\n",
      "  Theta     Score                                              Param\n",
      "0     1   0.52531  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "1     2  0.525324  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "2     4  0.513502  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "3     7  0.516792  [{'C': 100, 'fit_intercept': True, 'intercept_...\n",
      "4    11  0.511822  [{'C': 0.1, 'fit_intercept': True, 'intercept_...\n",
      "5    16  0.511822  [{'C': 1, 'fit_intercept': True, 'intercept_sc...\n",
      "6    22  0.511822  [{'C': 10, 'fit_intercept': True, 'intercept_s...\n",
      "\n",
      " 5 of 5 ACC: 0.4939759036144578\n",
      "\n",
      "\n",
      " whole_ACC: 0.4771084337349398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create whole test dataframe ###\n",
    "whole_result = pd.DataFrame()\n",
    "\n",
    "for num in range(5):\n",
    "\n",
    "    ### import data ###\n",
    "    ticker_data = data[data['ticker']==TICKER].reset_index(drop=True)\n",
    "    ticker_data = ticker_data.drop(columns=['ticker'])\n",
    "\n",
    "    # SMA-P/P, binary classification #\n",
    "    ticker_data[f'y_{TP}'] = ticker_data['close'].rolling(window=TP).mean()\n",
    "    ticker_data[f'y_{TP}'] = ticker_data[f'y_{TP}'].shift(-TP)\n",
    "    ticker_data = ticker_data.dropna().reindex()\n",
    "    ticker_data[f'y_{TP}'] = ((ticker_data[f'y_{TP}'] - ticker_data['close']) >= 0).astype(int)\n",
    "\n",
    "    origi_data = ticker_data.copy() # Dataframe for validation\n",
    "\n",
    "    # Restore to a dataframe without disclosing future information. #\n",
    "    ticker_data[f'y_{TP}'] = ticker_data[f'y_{TP}'].shift(TP)\n",
    "    ticker_data = ticker_data.dropna().reset_index(drop=True)\n",
    "\n",
    "    # Splite Library and Prediction #\n",
    "    Library = ticker_data[ticker_data['Date'] <= '2023-06-30'] # the last prediction from Library is 6/30\n",
    "    Prediction = ticker_data[(ticker_data['Date'] >= '2023-07-01')&(ticker_data['Date'] <= '2023-10-31')] \n",
    "\n",
    "    ### Create a dataframe for prediction results. ###\n",
    "    Date = origi_data['Date'][(origi_data['Date']>='2023-07-01')&(origi_data['Date']<='2023-10-31')].reset_index(drop=True)\n",
    "    Observations = origi_data[TARGET][(origi_data['Date']>='2023-07-01')&(origi_data['Date']<='2023-10-31')].reset_index(drop=True)\n",
    "\n",
    "    EDM_result = pd.DataFrame(Date)\n",
    "    EDM_result['Observations'] = Observations\n",
    "    EDM_result['Predictions'] = None\n",
    "\n",
    "    ### Starting from Pred[0] (include searching views for EDM). ###\n",
    "    th=0\n",
    "    Lib_Pred_df = ConcateLibPred(Library=Library, Prediction=Prediction, th=th)\n",
    "    Lib_Pred_df = DataNormalize(Lib_Pred_df=Lib_Pred_df)\n",
    "\n",
    "    formatted_columns, train_feature = EDM_FeatureProcessing(data=Lib_Pred_df, target=TARGET)\n",
    "    TargetOED, TargetOED_rho = EDM_TargetOED(data=Lib_Pred_df, target=TARGET, valid_interval=60)\n",
    "    f_selec = EDM_FeatureSelection(data=Lib_Pred_df, target=TARGET, \n",
    "                                train_feature=train_feature, TargetOED=TargetOED, \n",
    "                                E_max=EMAX)\n",
    "    Embed_df, ML_df = EDM_CreateNewDF(data=Lib_Pred_df, target=TARGET, f_selec=f_selec, \n",
    "                                    max_lag=MAXLAG, th=th)\n",
    "    rs_score = EDM_RandomSimplex(Embed_df=Embed_df, target=TARGET, targetOED=TargetOED, \n",
    "                                valid_interval=60, kmax=10000, kn=KN)\n",
    "    dmatrix = EDM_WeightedDistanceMatrix(Embed_df=Embed_df, rs_score=rs_score)\n",
    "    result_ls, theta, param = EDM_ModelSelection(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                                                theta_seq=THETA_SEQ, Tp=TP)\n",
    "    model = EDM_TrainningModel(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                            theta=theta, param=param, Tp=TP)\n",
    "\n",
    "    X_pred = np.array(ML_df.iloc[-1]).reshape(1, -1)\n",
    "    y_pred = model.predict(X_pred)\n",
    "    y_pred = y_pred[0]\n",
    "\n",
    "    EDM_result.loc[th, 'Predictions'] = y_pred\n",
    "    # print(f\"{EDM_result['Date'][th]}: finished\")\n",
    "\n",
    "    ### Predict the remaining ###\n",
    "    for th in range(1, len(Prediction)):\n",
    "        Library = UnderSampling(Library=Library, target=TARGET)\n",
    "        Lib_Pred_df = ConcateLibPred(Library=Library, Prediction=Prediction, th=th)\n",
    "        Lib_Pred_df = DataNormalize(Lib_Pred_df=Lib_Pred_df)\n",
    "        Embed_df, ML_df = EDM_CreateNewDF(data=Lib_Pred_df, target=TARGET, f_selec=f_selec, \n",
    "                                        max_lag=MAXLAG, th=th)\n",
    "        dmatrix = EDM_WeightedDistanceMatrix(Embed_df=Embed_df, rs_score=rs_score)\n",
    "        model = EDM_TrainningModel(ML_df=ML_df, target=TARGET, dmatrix=dmatrix, \n",
    "                                theta=theta, param=param, Tp=TP)\n",
    "        \n",
    "        X_pred = np.array(ML_df.iloc[-1]).reshape(1, -1)\n",
    "        y_pred = model.predict(X_pred)\n",
    "        y_pred = y_pred[0]\n",
    "\n",
    "        EDM_result.loc[th, 'Predictions'] = y_pred\n",
    "        # print(f\"{EDM_result['Date'][th]}: finished\")\n",
    "\n",
    "    EDM_result.dropna(inplace=True)\n",
    "    ACC = len(EDM_result[EDM_result['Predictions'] == EDM_result['Observations']]) / len(EDM_result['Observations'])\n",
    "    print(f'\\n {num+1} of 5 ACC: {ACC}\\n')\n",
    "\n",
    "    whole_result = pd.concat([whole_result, EDM_result], axis=0, ignore_index=True)\n",
    "\n",
    "# whole_result.to_csv(f'{TICKER}_MDRSmap_Tp={TP}_ResultWhole.csv', index=False)\n",
    "whole_ACC = len(whole_result[whole_result['Predictions'] == whole_result['Observations']]) / len(whole_result['Observations'])\n",
    "print(f'\\n whole_ACC: {whole_ACC}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
